To-do list:

[x] Get the HuggingFace dataset
[x] Get the Cohere API key
[] Explore and Preprocess the dataset
    - Do we need to step-ify the data?
    - Some of the problems are already in a step-ified format, but some are not.
    - Do we want to filter the number of records we use?
[] Perturb the dataset 
    - Which model should we use to perturb the data, if we want to start by exploring off-policy?
    - What prompt should we use to perturb the data?
        - I've noticed that sometimes the model is "rewriting" the user's solution, rather than rephrasing it.
            - I'm not sure whether it's adding material differences or not.
        - Can we (stepify-and-)perturb-and-truncate it one-shot, or do we need to do it in multiple steps?
        - I used the prompt generator tool here: https://console.anthropic.com/dashboard
            - It made a good point that we don't necessarily need to provide the question along with the solution; it should be possible
            to provide the steps of the solution without knowing the question... though I wonder if it would help (or hurt - would it encourage rewriting?) to provide it.

TOMORROW:
- Create the prompt using the aNthropic generator for the "perturb" step.
- Include in the prmopt the taxonomy
- Use the two (or more) examples you already posted in Slack


Meeting to-do:
- Decide how to handle the truncation
    - Ask the model to do it, or try to have a roughly even distribution and do it programmatically?
- Decide which models to test the recovery on
    - Only on non-base models, right?
- Decide how to detect the recovery
- Should I be having 15-25s latency? 
- I used the default temperature of 0.3 for the perturb step, which seems to work well, but should I be using 0 as a temp??


Problems I've been having (and have mostly addressed):
- Model is explicitly including the type of perturbation applied, in the steps (eg [Perturbation: Wrong Formula])
- Model is including the change applied (eg ...is also $1+x > 0$ (instead of $1-x > 0$))
- Problems with adherence to the instructions -- might only output a perturbed chain, and none of the other information.
    - Should I have it select the random step and the perturbation type before generating the perturbed output?
- It seems like the OpenAI Python library used to support a client.chat.completions API that let you 
set the history for user and model... but that's been deprecated. Unsure if I still can

-----

I don't see how it's possible to continue a generation 
using the OpenAI API.

I think I recall seeing recently a post (and 
I think I saved it or took a screnshot of it on twitter) regarding
using the Calude API to continue generations.


Use "Question" instead of "Problem"
Use "Solution"

----------- Oct 3 2024 -----------
Observed
- Some incorrect questions/answers in the dataset
- Completion behavior
    - Restarting CoT and ignoring perturbed
    - Playing given perturbation to completion and not recognizing error (free response)
    - Playing given perturabtion to completion and recognizing error only because it's not in the MC options

Doing:
- Cohere raw completions @ Jimin
- Confirming that I can't do raw completion with OpenAI
- Updating prompt for completion to increase adherence @ Eddie
- Comparisons of temperature for perturbation

I was having some problems about the perturbation basically just changing the final answer in the series of steps,
and my current prompt says something like "preference the second or third step in the reasoning chain, assuming they aren't 
terminal steps, but choose one where your selected perturbation type makes sense to apply. Is that okay, or do we want a more potentially-uniform
distribution of steps? I also had the idea that an earlier perturbation might give more time for an inflighnt recovery.
I think another result of it unfortunately was that the perturbations at different temperatures are more likely to be the same,
because they're all preferencing the same steps.I could do something like ask the model output whether it's a two-step problem,
and to ask it to output how many steps are in the problem, and then output what the reasonable range of steps to perturb would be,
and then select a step from that range that makes sense to perturb, given the selected perturbation type.

Decision on temperature for perturbation?
- For the low N that I've examined closely, it seems like T=0 and T=0.3 are basically indistiguishable
- We could do a variety of perturbations at different temperatures and ask an LM for the best one (or have it rate them with a rubric, or explanation -> rate)

TODO:
[] Some real shots for the stepification and perturbation pipeline
[] Another prompt to help me parse whether recovery occurred (immediately, after a few steps, or after arriving at an answer) and whether a right answer was reached
[] Propmt for detection of recovery and correctness
[] What inference provider for other models?
[] What analysis do we want to run?
    - Right now I'm running standard temperature for completions, but we wanted to run at varying temperatures and compare recoveries
    - 
----
